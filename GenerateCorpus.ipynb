{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized file 1 out of 130\n",
      "Normalized file 2 out of 130\n",
      "Normalized file 3 out of 130\n",
      "Normalized file 4 out of 130\n",
      "Normalized file 5 out of 130\n",
      "Normalized file 6 out of 130\n",
      "Normalized file 7 out of 130\n",
      "Normalized file 8 out of 130\n",
      "Normalized file 9 out of 130\n",
      "Normalized file 10 out of 130\n",
      "Normalized file 11 out of 130\n",
      "Normalized file 12 out of 130\n",
      "Normalized file 13 out of 130\n",
      "Normalized file 14 out of 130\n",
      "Normalized file 15 out of 130\n",
      "Normalized file 16 out of 130\n",
      "Normalized file 17 out of 130\n",
      "Normalized file 18 out of 130\n",
      "Normalized file 19 out of 130\n",
      "Normalized file 20 out of 130\n",
      "Normalized file 21 out of 130\n",
      "Normalized file 22 out of 130\n",
      "Normalized file 23 out of 130\n",
      "Normalized file 24 out of 130\n",
      "Normalized file 25 out of 130\n",
      "Normalized file 26 out of 130\n",
      "Normalized file 27 out of 130\n",
      "Normalized file 28 out of 130\n",
      "Normalized file 29 out of 130\n",
      "Normalized file 30 out of 130\n",
      "Normalized file 31 out of 130\n",
      "Normalized file 32 out of 130\n",
      "Normalized file 33 out of 130\n",
      "Normalized file 34 out of 130\n",
      "Normalized file 35 out of 130\n",
      "Exception normalizing file 36 out of 130 ( Fugue12.mid )\n",
      "Normalized file 37 out of 130\n",
      "Normalized file 38 out of 130\n",
      "Normalized file 39 out of 130\n",
      "Normalized file 40 out of 130\n",
      "Normalized file 41 out of 130\n",
      "Normalized file 42 out of 130\n",
      "Exception normalizing file 43 out of 130 ( Fugue19.mid )\n",
      "Normalized file 44 out of 130\n",
      "Normalized file 45 out of 130\n",
      "Normalized file 46 out of 130\n",
      "Normalized file 47 out of 130\n",
      "Normalized file 48 out of 130\n",
      "Normalized file 49 out of 130\n",
      "Normalized file 50 out of 130\n",
      "Normalized file 51 out of 130\n",
      "Normalized file 52 out of 130\n",
      "Normalized file 53 out of 130\n",
      "Normalized file 54 out of 130\n",
      "Normalized file 55 out of 130\n",
      "Normalized file 56 out of 130\n",
      "Normalized file 57 out of 130\n",
      "Exception normalizing file 58 out of 130 ( Fugue6.mid )\n",
      "Normalized file 59 out of 130\n",
      "Normalized file 60 out of 130\n",
      "Normalized file 61 out of 130\n",
      "Normalized file 62 out of 130\n",
      "Normalized file 63 out of 130\n",
      "Normalized file 64 out of 130\n",
      "Normalized file 65 out of 130\n",
      "Normalized file 66 out of 130\n",
      "Normalized file 67 out of 130\n",
      "Normalized file 68 out of 130\n",
      "Normalized file 69 out of 130\n",
      "Normalized file 70 out of 130\n",
      "Normalized file 71 out of 130\n",
      "Normalized file 72 out of 130\n",
      "Normalized file 73 out of 130\n",
      "Normalized file 74 out of 130\n",
      "Normalized file 75 out of 130\n",
      "Normalized file 76 out of 130\n",
      "Normalized file 77 out of 130\n",
      "Normalized file 78 out of 130\n",
      "Normalized file 79 out of 130\n",
      "Normalized file 80 out of 130\n",
      "Normalized file 81 out of 130\n",
      "Normalized file 82 out of 130\n",
      "Normalized file 83 out of 130\n",
      "Normalized file 84 out of 130\n",
      "Normalized file 85 out of 130\n",
      "Normalized file 86 out of 130\n",
      "Normalized file 87 out of 130\n",
      "Exception normalizing file 88 out of 130 ( Prelude13.mid )\n",
      "Exception normalizing file 89 out of 130 ( Prelude14.mid )\n",
      "Exception normalizing file 90 out of 130 ( Prelude15.mid )\n",
      "Normalized file 91 out of 130\n",
      "Normalized file 92 out of 130\n",
      "Normalized file 93 out of 130\n",
      "Exception normalizing file 94 out of 130 ( Prelude19.mid )\n",
      "Normalized file 95 out of 130\n",
      "Normalized file 96 out of 130\n",
      "Exception normalizing file 97 out of 130 ( Prelude20.mid )\n",
      "Normalized file 98 out of 130\n",
      "Normalized file 99 out of 130\n",
      "Normalized file 100 out of 130\n",
      "Normalized file 101 out of 130\n",
      "Normalized file 102 out of 130\n",
      "Normalized file 103 out of 130\n",
      "Normalized file 104 out of 130\n",
      "Normalized file 105 out of 130\n",
      "Normalized file 106 out of 130\n",
      "Normalized file 107 out of 130\n",
      "Normalized file 108 out of 130\n",
      "Normalized file 109 out of 130\n",
      "Normalized file 110 out of 130\n",
      "Normalized file 111 out of 130\n",
      "Normalized file 112 out of 130\n",
      "Normalized file 113 out of 130\n",
      "Normalized file 114 out of 130\n",
      "Normalized file 115 out of 130\n",
      "Normalized file 116 out of 130\n",
      "Normalized file 117 out of 130\n",
      "Normalized file 118 out of 130\n",
      "Normalized file 119 out of 130\n",
      "Normalized file 120 out of 130\n",
      "Normalized file 121 out of 130\n",
      "Normalized file 122 out of 130\n",
      "Normalized file 123 out of 130\n",
      "Normalized file 124 out of 130\n",
      "Normalized file 125 out of 130\n",
      "Normalized file 126 out of 130\n",
      "Normalized file 127 out of 130\n",
      "Normalized file 128 out of 130\n",
      "Normalized file 129 out of 130\n",
      "Normalized file 130 out of 130\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "# Loosely inspired by: https://github.com/anbrjohn/BachMaker/blob/master/get_training_data.py\n",
    "# Time-out code: https://stackoverflow.com/questions/25027122/break-the-function-after-certain-time\n",
    "\n",
    "\n",
    "# Code to generate a corpus of midi files by scraping from a webpage and augmenting the data set\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from music21 import converter, interval, pitch\n",
    "from music21.midi import MidiException\n",
    "import time\n",
    "import os\n",
    "import signal\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "# Custom exception class for time-out\n",
    "class TimeoutException(Exception):   \n",
    "    pass\n",
    "\n",
    "# Custom signal handler\n",
    "def timeout_handler(signum, frame):   \n",
    "    raise TimeoutException\n",
    "    \n",
    "# Change the behavior of SIGALRM\n",
    "#signal.signal(signal.SIGALRM, timeout_handler)\n",
    "\n",
    "\n",
    "# Scraping function returns list of files matching arguments\n",
    "def scrape(webpage, extension='.mid'):\n",
    "    \n",
    "    # Request html\n",
    "    u = urlopen(webpage)\n",
    "    try:\n",
    "        html = u.read()\n",
    "    finally:\n",
    "        u.close()\n",
    "    \n",
    "    # Find files of type 'extension'\n",
    "    files = []\n",
    "    for link in BeautifulSoup(html, parseOnlyThese=SoupStrainer('a')):\n",
    "        if link.has_attr('href'):\n",
    "            linkname = link['href']\n",
    "            if linkname[-len(extension):] == extension:\n",
    "                files += [linkname]\n",
    "    return files    \n",
    "\n",
    "\n",
    "# Downloads files from list if they don't already exist in specified dest_dir\n",
    "def download(prefix, dest_dir, files, delay=0):\n",
    "\n",
    "    # Given a list of files from a webpage, download them to directory\n",
    "    total = len(files)\n",
    "    i = 1\n",
    "    for file in files:\n",
    "        filename = prefix+file\n",
    "        new_file = os.path.join(dest_dir, file.replace('/', '_'))\n",
    "        if not os.path.exists(new_file):\n",
    "            urlretrieve(filename, new_file)\n",
    "            time.sleep(delay)\n",
    "        print(\"Downloaded file\", i, \"out of\", total)\n",
    "        i += 1\n",
    "        \n",
    "\n",
    "# Augments midis in source_dir and saves them to dest_dir based on a list of intervals\n",
    "def augment_midis(source_dir, dest_dir, intervals=['P1', 'M2', 'M3', 'M6', 'M7', 'P4', 'P5'], timeout=30):\n",
    "    \n",
    "    # Check if destination exists and create if not\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "    \n",
    "    # Iterate over midis in directory\n",
    "    midi_list = [file for file in os.listdir(source_dir) if file.endswith('.mid')]\n",
    "    total = len(midi_list)\n",
    "    i = 1\n",
    "    for file in midi_list:\n",
    "        # Set time-out alarm (seconds) in case transposing is taking too long\n",
    "        #signal.alarm(timeout)\n",
    "        try:\n",
    "            s1 = converter.parse(os.path.join(source_dir,file))\n",
    "            for interval in intervals:\n",
    "                augmented_midi = os.path.join(dest_dir, os.path.splitext(os.path.basename(file))[0]+'_'+interval+'.mid')\n",
    "                # Only augment if it hasn't already been done\n",
    "                if not os.path.exists(augmented_midi):\n",
    "                    s2 = s1.transpose(interval)\n",
    "                    s2.write('midi', augmented_midi)\n",
    "        except TimeoutException:\n",
    "            print(\"Time-out augmenting file\", i, \"out of\", total, \"(\", file, \")\")\n",
    "            continue\n",
    "        except (MidiException, IndexError):\n",
    "            print(\"Exception augmenting file\", i, \"out of\", total, \"(\", file, \")\")\n",
    "            continue\n",
    "        else:\n",
    "            #signal.alarm(0)\n",
    "            print(\"Augmented file\", i, \"out of\", total)\n",
    "        finally:\n",
    "            i += 1\n",
    "\n",
    "# Normalize midis in source_dir to a consistent key\n",
    "def normalize_midis(source_dir, dest_dir, final_pitch='C', timeout=30):\n",
    "    \n",
    "    # Check if destination exists and create if not\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "    \n",
    "    # Iterate over midis in directory\n",
    "    midi_list = [file for file in os.listdir(source_dir) if file.endswith('.mid')]\n",
    "    total = len(midi_list)\n",
    "    i = 1\n",
    "    for file in midi_list:\n",
    "        # Set time-out alarm (seconds) in case transposing is taking too long\n",
    "        #signal.alarm(timeout)\n",
    "        try:\n",
    "            normalized_midi = os.path.join(dest_dir, os.path.splitext(os.path.basename(file))[0]+'_'+final_pitch+'.mid')\n",
    "            # Only normalize if it hasn't already been done\n",
    "            if not os.path.exists(normalized_midi):\n",
    "                s1 = converter.parse(os.path.join(source_dir,file))\n",
    "                s1_k = s1.analyze('key')\n",
    "                s1_i = interval.Interval(s1_k.tonic, pitch.Pitch(final_pitch))\n",
    "                s2 = s1.transpose(s1_i)\n",
    "                s2.write('midi', normalized_midi)\n",
    "        except TimeoutException:\n",
    "            print(\"Time-out normalizing file\", i, \"out of\", total, \"(\", file, \")\")\n",
    "            continue\n",
    "        except (MidiException, IndexError):\n",
    "            print(\"Exception normalizing file\", i, \"out of\", total, \"(\", file, \")\")\n",
    "            continue\n",
    "        else:\n",
    "            #signal.alarm(0)\n",
    "            print(\"Normalized file\", i, \"out of\", total)\n",
    "        finally:\n",
    "            i += 1\n",
    "            \n",
    "            \n",
    "# Location of download links\n",
    "webpage = \"http://www.bachcentral.com/midiindexcomplete.html\"\n",
    "\n",
    "# What all the download links begin with\n",
    "file_prefix = \"http://www.bachcentral.com/\"\n",
    "\n",
    "# Destination directory\n",
    "output = './pianomidi/'\n",
    "\n",
    "# Destination directory for augmented dataset\n",
    "augmented = './bach_midis/augmented/'\n",
    "\n",
    "# Destination directory for augmented dataset\n",
    "normalized = './pianomidi/normalized/'\n",
    "\n",
    "\n",
    "#corpus = scrape(webpage)\n",
    "#download(file_prefix, output, corpus, 2)\n",
    "#augment_midis(output, augmented, timeout=90)\n",
    "normalize_midis(output, normalized, timeout=90)\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized file 1 out of 130\n",
      "Tokenized file 2 out of 130\n",
      "Tokenized file 3 out of 130\n",
      "Tokenized file 4 out of 130\n",
      "Tokenized file 5 out of 130\n",
      "Tokenized file 6 out of 130\n",
      "Tokenized file 7 out of 130\n",
      "Tokenized file 8 out of 130\n",
      "Tokenized file 9 out of 130\n",
      "Tokenized file 10 out of 130\n",
      "Tokenized file 11 out of 130\n",
      "Tokenized file 12 out of 130\n",
      "Tokenized file 13 out of 130\n",
      "Tokenized file 14 out of 130\n",
      "Tokenized file 15 out of 130\n",
      "Tokenized file 16 out of 130\n",
      "Tokenized file 17 out of 130\n",
      "Tokenized file 18 out of 130\n",
      "Tokenized file 19 out of 130\n",
      "Tokenized file 20 out of 130\n",
      "Tokenized file 21 out of 130\n",
      "Tokenized file 22 out of 130\n",
      "Tokenized file 23 out of 130\n",
      "Tokenized file 24 out of 130\n",
      "Tokenized file 25 out of 130\n",
      "Tokenized file 26 out of 130\n",
      "Tokenized file 27 out of 130\n",
      "Tokenized file 28 out of 130\n",
      "Tokenized file 29 out of 130\n",
      "Tokenized file 30 out of 130\n",
      "Tokenized file 31 out of 130\n",
      "Tokenized file 32 out of 130\n",
      "Tokenized file 33 out of 130\n",
      "Tokenized file 34 out of 130\n",
      "Tokenized file 35 out of 130\n",
      "Exception tokenizing file 36 out of 130 ( Fugue12.mid )\n",
      "Tokenized file 37 out of 130\n",
      "Tokenized file 38 out of 130\n",
      "Tokenized file 39 out of 130\n",
      "Tokenized file 40 out of 130\n",
      "Tokenized file 41 out of 130\n",
      "Tokenized file 42 out of 130\n",
      "Exception tokenizing file 43 out of 130 ( Fugue19.mid )\n",
      "Tokenized file 44 out of 130\n",
      "Tokenized file 45 out of 130\n",
      "Tokenized file 46 out of 130\n",
      "Tokenized file 47 out of 130\n",
      "Tokenized file 48 out of 130\n",
      "Tokenized file 49 out of 130\n",
      "Tokenized file 50 out of 130\n",
      "Tokenized file 51 out of 130\n",
      "Tokenized file 52 out of 130\n",
      "Tokenized file 53 out of 130\n",
      "Tokenized file 54 out of 130\n",
      "Tokenized file 55 out of 130\n",
      "Tokenized file 56 out of 130\n",
      "Tokenized file 57 out of 130\n",
      "Exception tokenizing file 58 out of 130 ( Fugue6.mid )\n",
      "Tokenized file 59 out of 130\n",
      "Tokenized file 60 out of 130\n",
      "Tokenized file 61 out of 130\n",
      "Tokenized file 62 out of 130\n",
      "Tokenized file 63 out of 130\n",
      "Tokenized file 64 out of 130\n",
      "Tokenized file 65 out of 130\n",
      "Tokenized file 66 out of 130\n",
      "Tokenized file 67 out of 130\n",
      "Tokenized file 68 out of 130\n",
      "Tokenized file 69 out of 130\n",
      "Tokenized file 70 out of 130\n",
      "Tokenized file 71 out of 130\n",
      "Tokenized file 72 out of 130\n",
      "Tokenized file 73 out of 130\n",
      "Tokenized file 74 out of 130\n",
      "Tokenized file 75 out of 130\n",
      "Tokenized file 76 out of 130\n",
      "Tokenized file 77 out of 130\n",
      "Tokenized file 78 out of 130\n",
      "Tokenized file 79 out of 130\n",
      "Tokenized file 80 out of 130\n",
      "Tokenized file 81 out of 130\n",
      "Tokenized file 82 out of 130\n",
      "Tokenized file 83 out of 130\n",
      "Tokenized file 84 out of 130\n",
      "Tokenized file 85 out of 130\n",
      "Tokenized file 86 out of 130\n",
      "Tokenized file 87 out of 130\n",
      "Exception tokenizing file 88 out of 130 ( Prelude13.mid )\n",
      "Exception tokenizing file 89 out of 130 ( Prelude14.mid )\n",
      "Exception tokenizing file 90 out of 130 ( Prelude15.mid )\n",
      "Tokenized file 91 out of 130\n",
      "Tokenized file 92 out of 130\n",
      "Tokenized file 93 out of 130\n",
      "Exception tokenizing file 94 out of 130 ( Prelude19.mid )\n",
      "Tokenized file 95 out of 130\n",
      "Tokenized file 96 out of 130\n",
      "Exception tokenizing file 97 out of 130 ( Prelude20.mid )\n",
      "Tokenized file 98 out of 130\n",
      "Tokenized file 99 out of 130\n",
      "Tokenized file 100 out of 130\n",
      "Tokenized file 101 out of 130\n",
      "Tokenized file 102 out of 130\n",
      "Tokenized file 103 out of 130\n",
      "Tokenized file 104 out of 130\n",
      "Tokenized file 105 out of 130\n",
      "Tokenized file 106 out of 130\n",
      "Tokenized file 107 out of 130\n",
      "Tokenized file 108 out of 130\n",
      "Tokenized file 109 out of 130\n",
      "Tokenized file 110 out of 130\n",
      "Tokenized file 111 out of 130\n",
      "Tokenized file 112 out of 130\n",
      "Tokenized file 113 out of 130\n",
      "Tokenized file 114 out of 130\n",
      "Tokenized file 115 out of 130\n",
      "Tokenized file 116 out of 130\n",
      "Tokenized file 117 out of 130\n",
      "Tokenized file 118 out of 130\n",
      "Tokenized file 119 out of 130\n",
      "Tokenized file 120 out of 130\n",
      "Tokenized file 121 out of 130\n",
      "Tokenized file 122 out of 130\n",
      "Tokenized file 123 out of 130\n",
      "Tokenized file 124 out of 130\n",
      "Tokenized file 125 out of 130\n",
      "Tokenized file 126 out of 130\n",
      "Tokenized file 127 out of 130\n",
      "Tokenized file 128 out of 130\n",
      "Tokenized file 129 out of 130\n",
      "Tokenized file 130 out of 130\n",
      "Tokens written to ./ling_corpus_tokens.txt\n",
      "Vocabulary size is 53\n",
      "Tokenize normalized complete!\n"
     ]
    }
   ],
   "source": [
    "# Loosely inspired by: https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "\n",
    "\n",
    "# From a corpus of midi files, generate training tokens for MaskGAN\n",
    "\n",
    "\n",
    "from music21 import converter, instrument, note, chord\n",
    "from music21.midi import MidiException\n",
    "import time\n",
    "import os\n",
    "import signal\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "# Custom exception class for time-out\n",
    "class TimeoutException(Exception):   \n",
    "    pass\n",
    "\n",
    "# Custom signal handler\n",
    "def timeout_handler(signum, frame):   \n",
    "    raise TimeoutException\n",
    "\n",
    "# Change the behavior of SIGALRM\n",
    "#signal.signal(signal.SIGALRM, timeout_handler)\n",
    "\n",
    "\n",
    "# Tokenize midis in source_dir for training sequence model\n",
    "def tokenize_midis(source_dir, dest_file, timeout=30, chordify=False, rests=False):\n",
    "    \n",
    "    # Iterate over midis in directory\n",
    "    midi_list = [file for file in os.listdir(source_dir) if file.endswith('.mid')]\n",
    "    total = len(midi_list)\n",
    "    i = 1\n",
    "    outfile = open(dest_file, 'w')\n",
    "    \n",
    "    for file in midi_list:\n",
    "        tokens = []\n",
    "        # Set time-out alarm (seconds) in case transposing is taking too long\n",
    "        #signal.alarm(timeout)\n",
    "        try:\n",
    "            s1 = converter.parse(os.path.join(source_dir,file))\n",
    "            if chordify:\n",
    "                s1 = s1.chordify()\n",
    "            notes_to_parse = None\n",
    "            parts = instrument.partitionByInstrument(s1)\n",
    "            if parts: # file has instrument parts\n",
    "                notes_to_parse = parts.parts[0].recurse()\n",
    "            else: # file has notes in a flat structure\n",
    "                notes_to_parse = s1.flat.notes\n",
    "            for element in notes_to_parse:\n",
    "                if isinstance(element, note.Note):\n",
    "                    tokens.append(str(element.pitch))\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    tokens.append(element.root().name + str(element.root().octave))\n",
    "                elif isinstance(element, note.Rest):\n",
    "                    if rests:\n",
    "                        tokens.append('rest')\n",
    "        except TimeoutException:\n",
    "            print(\"Time-out tokenizing file\", i, \"out of\", total, \"(\", file, \")\")\n",
    "            continue\n",
    "        except (MidiException, IndexError, TypeError):\n",
    "            print(\"Exception tokenizing file\", i, \"out of\", total, \"(\", file, \")\")\n",
    "            continue\n",
    "        else:\n",
    "            #signal.alarm(0)\n",
    "            print(\"Tokenized file\", i, \"out of\", total)\n",
    "        finally:\n",
    "            i += 1\n",
    "        \n",
    "        outfile.write(\" \".join(tokens)+\"\\n\")\n",
    "        \n",
    "    outfile.close()\n",
    "    print('Tokens written to %s' % dest_file)\n",
    "    print('Vocabulary size is %i' % len(set(w for w in open(dest_file).read().split())))\n",
    "\n",
    "#tokenize_midis('./bach_midis/', './original_corpus_tokens.txt')\n",
    "#print('Tokenize original complete!')\n",
    "#tokenize_midis('./augmented/', './ling_augmented_corpus_tokens2.txt')\n",
    "#print('Tokenize augmented complete!')\n",
    "#tokenize_midis('./pianomidi/normalized/', './ling_normalized_corpus_tokens.txt')\n",
    "#print('Tokenize normalized complete!')\n",
    "tokenize_midis('./pianomidi/', './ling_corpus_tokens.txt')\n",
    "print('Tokenize normalized complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
